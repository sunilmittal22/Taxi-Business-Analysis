{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pyspark\n",
      "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
      "Collecting py4j==0.10.9.7\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "Building wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py): started\n",
      "  Building wheel for pyspark (setup.py): still running...\n",
      "  Building wheel for pyspark (setup.py): finished with status 'done'\n",
      "  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285425 sha256=717c26d08a7d7d3eb60fb83a65283122ba33d530ffa21c5edb98f7391d8ad9c1\n",
      "  Stored in directory: c:\\users\\sunil\\appdata\\local\\pip\\cache\\wheels\\2b\\9a\\39\\d8019ffbfb76a39433455e3d5799e94d3e3cae8f41229f6bf8\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.7 pyspark-3.4.1\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-NVTONRRN:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>NYC Yellow Taxi Data Analysis</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x22872b159d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"NYC Yellow Taxi Data Analysis\") \\\n",
    "    .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|       1| 2020-06-01 00:31:23|  2020-06-01 00:49:58|              1|          3.6|         1|                 N|         140|          68|           1|       15.5|  3.0|    0.5|       4.0|         0.0|                  0.3|        23.3|                 2.5|\n",
      "|       1| 2020-06-01 00:42:50|  2020-06-01 01:04:33|              1|          5.6|         1|                 N|          79|         226|           1|       19.5|  3.0|    0.5|       2.0|         0.0|                  0.3|        25.3|                 2.5|\n",
      "|       1| 2020-06-01 00:39:51|  2020-06-01 00:49:09|              1|          2.3|         1|                 N|         238|         116|           2|       10.0|  0.5|    0.5|       0.0|         0.0|                  0.3|        11.3|                 0.0|\n",
      "|       1| 2020-06-01 00:56:13|  2020-06-01 01:11:38|              1|          5.3|         1|                 N|         141|         116|           2|       17.5|  3.0|    0.5|       0.0|         0.0|                  0.3|        21.3|                 2.5|\n",
      "|       1| 2020-06-01 00:16:41|  2020-06-01 00:29:30|              1|          4.4|         1|                 N|         186|          75|           1|       14.5|  3.0|    0.5|      3.65|         0.0|                  0.3|       21.95|                 2.5|\n",
      "|       2| 2020-06-01 00:06:29|  2020-06-01 00:13:22|              1|         1.72|         1|                 N|         142|         186|           2|        8.0|  0.5|    0.5|       0.0|         0.0|                  0.3|        11.8|                 2.5|\n",
      "|       2| 2020-06-01 00:15:04|  2020-06-01 00:19:36|              1|         1.23|         1|                 N|         186|         234|           1|        6.0|  0.5|    0.5|      2.94|         0.0|                  0.3|       12.74|                 2.5|\n",
      "|       2| 2020-06-01 00:12:52|  2020-06-01 00:18:20|              1|         0.94|         1|                 N|         238|         151|           2|        6.0|  0.5|    0.5|       0.0|         0.0|                  0.3|         7.3|                 0.0|\n",
      "|       2| 2020-06-01 00:08:48|  2020-06-01 00:40:48|              2|         19.0|         2|                 N|         132|         113|           1|       52.0|  0.0|    0.5|     13.82|         0.0|                  0.3|       69.12|                 2.5|\n",
      "|       1| 2020-06-01 00:10:33|  2020-06-01 00:15:38|              0|          0.8|         1|                 N|          75|         263|           1|        5.5|  0.5|    0.5|       1.0|         0.0|                  0.3|         7.8|                 0.0|\n",
      "|       1| 2020-06-01 00:33:56|  2020-06-01 00:41:29|              1|          1.8|         1|                 N|          75|          24|           1|        8.0|  0.5|    0.5|       2.3|         0.0|                  0.3|        11.6|                 0.0|\n",
      "|       2| 2020-06-01 00:08:05|  2020-06-01 00:21:33|              1|         3.41|         1|                 N|         229|         238|           2|       13.0|  0.5|    0.5|       0.0|         0.0|                  0.3|        16.8|                 2.5|\n",
      "|       2| 2020-06-01 00:19:06|  2020-06-01 00:21:51|              1|         0.73|         1|                 N|         107|         224|           1|        4.5|  0.5|    0.5|      1.66|         0.0|                  0.3|        9.96|                 2.5|\n",
      "|       2| 2020-06-01 00:56:43|  2020-06-01 01:07:44|              1|          3.6|         1|                 N|          79|          25|           2|       12.5|  0.5|    0.5|       0.0|         0.0|                  0.3|        16.3|                 2.5|\n",
      "|       2| 2020-06-01 00:21:28|  2020-06-01 00:25:01|              1|         1.11|         1|                 N|         100|         249|           4|       -5.5| -0.5|   -0.5|       0.0|         0.0|                 -0.3|        -9.3|                -2.5|\n",
      "|       2| 2020-06-01 00:21:28|  2020-06-01 00:25:01|              1|         1.11|         1|                 N|         100|         249|           2|        5.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         9.3|                 2.5|\n",
      "|       2| 2020-06-01 00:56:47|  2020-06-01 01:14:20|              1|         8.31|         1|                 N|         186|         244|           1|       24.5|  0.5|    0.5|       3.0|         0.0|                  0.3|        31.3|                 2.5|\n",
      "|       2| 2020-06-01 00:22:56|  2020-06-01 00:59:09|              1|        12.81|         1|                 N|         186|         134|           1|       40.0|  0.5|    0.5|      8.76|         0.0|                  0.3|       52.56|                 2.5|\n",
      "|       1| 2020-06-01 00:14:36|  2020-06-01 00:24:54|              2|          3.5|         1|                 N|         107|         263|           1|       12.0|  3.0|    0.5|      3.95|         0.0|                  0.3|       19.75|                 2.5|\n",
      "|       1| 2020-06-01 00:28:17|  2020-06-01 00:33:47|              1|          1.4|         1|                 N|         236|         141|           2|        7.0|  3.0|    0.5|       0.0|         0.0|                  0.3|        10.8|                 2.5|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "df = spark.read.csv(\"D:/YellowTaxiData/yellow_tripdata_2020-06.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Show the first few records to verify that the DataFrame is created successfully\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count the number of taxi trips for each hour "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|pickup_hour|count|\n",
      "+-----------+-----+\n",
      "|          0| 8122|\n",
      "|          1| 6643|\n",
      "|          2| 5111|\n",
      "|          3| 5124|\n",
      "|          4| 7136|\n",
      "|          5| 6955|\n",
      "|          6|14907|\n",
      "|          7|19957|\n",
      "|          8|24824|\n",
      "|          9|28408|\n",
      "|         10|31948|\n",
      "|         11|35190|\n",
      "|         12|38083|\n",
      "|         13|39475|\n",
      "|         14|40525|\n",
      "|         15|40971|\n",
      "|         16|38627|\n",
      "|         17|38225|\n",
      "|         18|34181|\n",
      "|         19|26477|\n",
      "+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Extract the hour from the pickup datetime\n",
    "df_with_hour = df.withColumn(\"pickup_hour\", F.hour(F.col(\"tpep_pickup_datetime\")))\n",
    "\n",
    "# Count the number of trips for each hour\n",
    "hourly_counts = df_with_hour.groupBy(\"pickup_hour\").count().orderBy(\"pickup_hour\")\n",
    "\n",
    "# Show the result\n",
    "hourly_counts.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Create a table view of the data frame created in step 1 above and write SparkSQL queries to find out the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary table view for SQL queries\n",
    "df.createOrReplaceTempView(\"yellow_taxi_data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Average fare amount collected by hour of the day "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|hour|          avg_fare|\n",
      "+----+------------------+\n",
      "|   0|18.880695641467636|\n",
      "|   1|27.534966129760516|\n",
      "|   2| 30.12912737233405|\n",
      "|   3| 35.20126073380151|\n",
      "|   4|40.932777466367725|\n",
      "|   5|20.005923795830356|\n",
      "|   6|11.691494599852422|\n",
      "|   7|11.342811043744058|\n",
      "|   8|11.184160087012577|\n",
      "|   9|11.276688256829068|\n",
      "|  10|11.909430324276945|\n",
      "|  11| 11.99153282182437|\n",
      "|  12|11.864507260457398|\n",
      "|  13|11.580972260924616|\n",
      "|  14|12.048847378161604|\n",
      "|  15| 12.75542871787359|\n",
      "|  16|12.926983198280974|\n",
      "|  17| 13.05241726618704|\n",
      "|  18|12.484358269213883|\n",
      "|  19|12.241942818295119|\n",
      "+----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_fare_by_hour = spark.sql(\"\"\"\n",
    "    SELECT HOUR(tpep_pickup_datetime) as hour, AVG(fare_amount) as avg_fare\n",
    "    FROM yellow_taxi_data\n",
    "    GROUP BY hour\n",
    "    ORDER BY hour\n",
    "\"\"\")\n",
    "avg_fare_by_hour.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Average fare amount compared to the average trip distance –"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------+\n",
      "|          avg_fare|     avg_distance|\n",
      "+------------------+-----------------+\n",
      "|13.606733865686362|4.104275283760191|\n",
      "+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_fare_vs_distance = spark.sql(\"\"\"\n",
    "    SELECT AVG(fare_amount) as avg_fare, AVG(trip_distance) as avg_distance\n",
    "    FROM yellow_taxi_data\n",
    "\"\"\")\n",
    "avg_fare_vs_distance.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Average fare amount and average trip distance by day of the week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+------------------+\n",
      "|day_of_week|          avg_fare|      avg_distance|\n",
      "+-----------+------------------+------------------+\n",
      "|          1|14.686292601998968|3.9104436342782214|\n",
      "|          2|13.409943486081072| 4.262469750235038|\n",
      "|          3|13.449879403674744|3.2025723626895357|\n",
      "|          4|13.279588696533745|  6.04762380811827|\n",
      "|          5| 13.40498273892465| 3.999548450269279|\n",
      "|          6|13.702733958318653| 3.778188952327255|\n",
      "|          7|13.880926298071115| 3.602206763882438|\n",
      "+-----------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_fare_and_distance_by_day = spark.sql(\"\"\"\n",
    "    SELECT DAYOFWEEK(tpep_pickup_datetime) as day_of_week,\n",
    "           AVG(fare_amount) as avg_fare,\n",
    "           AVG(trip_distance) as avg_distance\n",
    "    FROM yellow_taxi_data\n",
    "    GROUP BY day_of_week\n",
    "    ORDER BY day_of_week\n",
    "\"\"\")\n",
    "avg_fare_and_distance_by_day.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the month of June 2020, find the zone which had maximum number of pick ups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|pickup_zone|num_pickups|\n",
      "+-----------+-----------+\n",
      "|        236|      23097|\n",
      "+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_pickup_zone = spark.sql(\"\"\"\n",
    "    SELECT PULocationID AS pickup_zone, COUNT(*) as num_pickups\n",
    "    FROM yellow_taxi_data\n",
    "    where month(tpep_pickup_datetime)=6 and year(tpep_pickup_datetime)=2020\n",
    "    GROUP BY pickup_zone\n",
    "    ORDER BY num_pickups DESC\n",
    "    LIMIT 1\n",
    "\"\"\")\n",
    "max_pickup_zone.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the month of June 2020, find the zone which had maximum number of drops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+\n",
      "|dropoff_zone|num_dropoffs|\n",
      "+------------+------------+\n",
      "|         236|       22254|\n",
      "+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_dropoff_zone = spark.sql(\"\"\"\n",
    "    SELECT DOLocationID AS  dropoff_zone, COUNT(*) as num_dropoffs\n",
    "    FROM yellow_taxi_data\n",
    "    where month(tpep_pickup_datetime)=6 and year(tpep_pickup_datetime)=2020\n",
    "    GROUP BY dropoff_zone\n",
    "    ORDER BY num_dropoffs DESC\n",
    "    LIMIT 1\n",
    "\"\"\")\n",
    "max_dropoff_zone.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.Average no of passengers by hour of the day. –"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|hour|    avg_passengers|\n",
      "+----+------------------+\n",
      "|   0|1.3300081766148815|\n",
      "|   1|1.2963541666666667|\n",
      "|   2| 1.308466051969824|\n",
      "|   3|1.3093270365997638|\n",
      "|   4|1.2861205915813425|\n",
      "|   5|1.3718697829716193|\n",
      "|   6|1.3303137428192664|\n",
      "|   7|1.3431017976810977|\n",
      "|   8| 1.359296915388592|\n",
      "|   9|1.3521955975550306|\n",
      "|  10| 1.361447777998543|\n",
      "|  11|1.3555843529624496|\n",
      "|  12|1.3567879870492352|\n",
      "|  13|1.3521634939012896|\n",
      "|  14|1.3638007863695938|\n",
      "|  15|1.3572915863345416|\n",
      "|  16|  1.35842077865147|\n",
      "|  17|1.3650200560470356|\n",
      "|  18| 1.376865328634901|\n",
      "|  19|1.3628078030060762|\n",
      "+----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_passengers_by_hour = spark.sql(\"\"\"\n",
    "    SELECT HOUR(tpep_pickup_datetime) as hour, AVG(passenger_count) as avg_passengers\n",
    "    FROM yellow_taxi_data\n",
    "    GROUP BY hour\n",
    "    ORDER BY hour\n",
    "\"\"\")\n",
    "avg_passengers_by_hour.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total number of payments made by different type for the month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------------+------------+\n",
      "|Year|Month|payment_type|num_payments|\n",
      "+----+-----+------------+------------+\n",
      "|2020|    6|           4|        2275|\n",
      "|2020|    5|           1|           1|\n",
      "|2020|    6|           1|      322565|\n",
      "|2020|    6|           3|        5245|\n",
      "|2020|    5|           2|           3|\n",
      "|2020|    6|           2|      168937|\n",
      "|2020|    6|           5|          12|\n",
      "|2009|    1|           2|           3|\n",
      "|2020|    6|        null|       50717|\n",
      "|2020|    7|           1|           2|\n",
      "+----+-----+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "payment_types = spark.sql(\"\"\"\n",
    "    SELECT year(tpep_pickup_datetime) AS Year, month(tpep_pickup_datetime) AS Month ,payment_type, COUNT(*) as num_payments\n",
    "    FROM yellow_taxi_data\n",
    "    GROUP BY year(tpep_pickup_datetime), month(tpep_pickup_datetime),payment_type\n",
    "\"\"\")\n",
    "payment_types.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
